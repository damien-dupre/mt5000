<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Tutorial 7: Advanced Linear Regression</title>
    <meta charset="utf-8" />
    <meta name="author" content="Damien Dupré" />
    <script src="tutorial_7_files/header-attrs-2.6.6/header-attrs.js"></script>
    <link rel="stylesheet" href="xaringan-themer.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Tutorial 7: Advanced Linear Regression
## MT5000 - Data Analytics &amp; Visualization
### Damien Dupré
### Dublin City University

---




# Objectives

In this tutorial we will see how to check if the linear regression has been properly applied:

- The 4 Assumptions of Linear Models
- More Assumptions

---

class: inverse, mline, center, middle

# 1. Assumptions of Linear Models

---

# Assumptions of Linear Models

People are using Linear Regression for all hypotheses testing, exactly how I just did but...

Linear Regression (as well as t-test and ANOVA) should be used **only if requirements are meet**:

#### 1. Linearity (of the effects). 

#### 2. Normality (of the residuals).

#### 4. Homogeneity (of the residuals)

#### 3. Independence (of observations)

While the assumption of a Linear Model are never perfectly met in reality, we must check if there are reasonable enough assumption that we can work with them.

---

# Assumptions 1: Linearity

A pretty fundamental assumption of the linear regression model is that the relationship between X and Y actually is linear.

**How to check it**: Plot the data and have a look (here simulated data)

&lt;img src="tutorial_7_files/figure-html/unnamed-chunk-1-1.png" width="720" style="display: block; margin: auto;" /&gt;

If the shape of the data is non linear then even the best linear model will have very big residuals and therefore very high `\(MSE\)` or `\(RMSE\)`.

---

# Assumptions 2: Normality

Like many of the models in statistics, simple or multiple linear regression relies on an assumption of normality. Specifically, **it assumes that the residuals are normally distributed**. **It's actually okay if the predictors X and the outcome Y are non-normal**, as long as the residuals `\(\epsilon\)` are normal.

Plot of the theoretical quantiles according to the model, against the quantiles of the standardised residuals (JAMOVI: Assumption Checks &gt; Q-Q plot of residuals).

&lt;img src="tutorial_7_files/figure-html/unnamed-chunk-2-1.png" width="720" style="display: block; margin: auto;" /&gt;

---

# Assumptions 3: Homogeneity

The regression model assumes that each residual `\(\epsilon\)` is generated from a normal distribution: **the standard deviation of the residual should be the same for all values of Y**. 

.pull-left[
In Jamovi, use **Residuals Plot** option providing a scatterplot for each predictor variable, the outcome variable, and the predicted values against residuals.

If the linearity assumption is met **we should see no pattern here, only a cloud of points**.
]

.pull-right[
&lt;img src="tutorial_7_files/figure-html/unnamed-chunk-3-1.png" width="360" style="display: block; margin: auto;" /&gt;
]

---

# Assumptions 4: Independent Residuals

To check this assumption, you need to know how the data were collected. **Is there a reason why two observations could be artificially related?**

&gt; For example, an experiment investigating marriage satisfaction according the duration of the marriage will be flawed if data are collected from both partners. Indeed the satisfaction from 1 member of the couple should be correlated to the satisfaction of the other couple. 

Make sure your participant does not know each others or then use the so called "linear mixed models".

In general, this is really just a "catch all" assumption, to the effect that "there's nothing else funny going on in the residuals". If there is something weird (e.g., the residuals all depend heavily on some other unmeasured variable) going on, it might screw things up.

---
class: inverse, mline, center, middle

# Live Demo with "employee_dd.xlsx"

---
class: inverse, mline, center, middle

# 2. More Assumptions

---

# Uncorrelated Predictors

In a multiple regression model, you don't want your predictors to be too strongly correlated with each other:

* This isn't technically an assumption of the regression model, but in practice it's required
* Predictors that are too strongly correlated with each other (referred to as collinearity) can cause problems when evaluating the model

### How to check it
- JAMOVI: **Regression &gt; Correlation Matrix &gt; Plot Correlation Matrix**

---

# Uncorrelated Predictors

.pull-left[
Imagine American scientist trying to predict individual's IQ by using their height, weight and the size of their brain.

**Variance Inflation Factors** (VIFs) is a very good measure of the extent to which a variable is correlated with all the other variables in the model. **A cut off value of 5 is commonly used**.

JAMOVI: **Regression &gt; Linear Regression: Assumption Checks "Collinearity statistics"**

]

.pull-right[
&lt;img src="tutorial_7_files/figure-html/unnamed-chunk-4-1.png" width="216" style="display: block; margin: auto;" /&gt;

&lt;table&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:left;"&gt; term &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; vif &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; tol &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; Brain &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 1.58 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.63 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; Height &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 2.28 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.44 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; Weight &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 2.02 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.49 &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

]

---

# No Anomalous Data

Again, not actually a technical assumption of the model (or rather, it's sort of implied by all the others), but there is **an implicit assumption that your regression model isn't being too strongly influenced by one or two anomalous data points** because this raises questions about the adequacy of the model and the trustworthiness of the data in some cases.

### Three kinds of anomalous data

- Harmless Outlier Observations
- High Leverage Observations
- High Influence Observations

---

# Harmless Outlier Observations

An "harmless" outliers is **an observation that is very different from what the regression model predicts**.

.pull-left[
Outliers are interesting: 

* A big outlier might correspond to junk data, e.g., the variables might have been recorded incorrectly in the data set, or some other defect may be detectable. 
* You shouldn't throw an observation away just because it's an outlier. But the fact that it's an outlier is often a cue to look more closely at that case and try to find out why it's so different.
]

.pull-right[
&lt;img src="tutorial_7_files/figure-html/unnamed-chunk-6-1.png" width="360" style="display: block; margin: auto;" /&gt;
]


---

# High Leverage Observations

The second way in which an observation can be unusual is if it has high leverage, which happens when the observation is **very different from all the other observations and influences the slope of the linear regression**. 

.pull-left[
This doesn't necessarily have to correspond to a large residual. 

If the observation happens to be unusual on all variables in precisely the same way, it can actually lie very close to the regression line.

High leverage points are also worth looking at in more detail, but they're much less likely to be a cause for concern.
]

.pull-right[
&lt;img src="tutorial_7_files/figure-html/unnamed-chunk-7-1.png" width="360" style="display: block; margin: auto;" /&gt;
]

---

# High Influence Observations

A high influence observation is an outlier that has high leverage. That is, it is **an observation that is
very different to all the other ones in some respect, and also lies a long way from the regression line**.

.pull-left[
We operationalise influence in terms of a measure known as **Cook's distance**. 

In Jamovi, information about Cook's distance can be calculated by clicking on the Cook's Distance' checkbox in the **Assumption Checks &gt; Data Summary** options. 

A Cook's distance greater than 1 is considered large.
]

.pull-right[
&lt;img src="tutorial_7_files/figure-html/unnamed-chunk-8-1.png" width="360" style="display: block; margin: auto;" /&gt;
]

---
class: inverse, mline, center, middle

# Live Demo with "employee_dd.xlsx"

---
class: inverse, mline, left, middle

&lt;img class="circle" src="https://github.com/damien-dupre.png" width="250px"/&gt;

# Thanks for your attention!
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "solarized-light",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
