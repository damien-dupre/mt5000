---
title: "MT5000 - Data Analytics & Visualization"
subtitle: "Lecture 11: Linear Regression in R"
author: "Damien Dupré"
date: "Dublin City University"
output:
  xaringan::moon_reader:
    css: ["default", "metropolis", "metropolis-fonts", "css/custom_design.css"]
    lib_dir: libs
    nature:
      beforeInit: "libs/cols_macro.js"
      highlightStyle: zenburn
      highlightLines: true
      countIncrementalSlides: false
---

```{r setup, include = FALSE}
# libraries --------------------------------------------------------------------
library(tidyverse)
library(knitr)
library(kableExtra)
library(fontawesome)
library(tweetrmd)
library(countdown)
library(gapminder)

# general options --------------------------------------------------------------
options(
  scipen = 999,
  htmltools.preserve.raw = FALSE
)
set.seed(42)
# chunk options ----------------------------------------------------------------
opts_chunk$set(
  cache.extra = rand_seed, 
  message = FALSE, 
  warning = FALSE, 
  error = FALSE, 
  echo = TRUE,
  cache = FALSE,
  comment = "", 
  fig.align = "center", 
  fig.retina = 3
  )

theme_update(
  text = element_text(size=20)
)

# functions --------------------------------------------------------------------
# https://bookdown.org/yihui/rmarkdown-cookbook/font-color.html#using-an-r-function-to-write-raw-html-or-latex-code

colorize <- function(x, color) {
  sprintf("<span style='color: %s;'>%s</span>", color, x)
  }
```

# R so far

We have already seen how to:

1. Transform data with `filter()`, `select()`, `mutate()`, `summarise()`, and `group_by()`
2. Visualise data with {ggplot2} from the {tidyverse}

The last step with R is to perform statistical analyses.

So far we have seen how to use R in RStudio Cloud but it has limits and it now time to use it on your own computer to deploy the full power of R

---

# Rstudio Cloud

In your webrowser (Chrome, Firefox, ...):

1. Open these same slides on a tab to copy-paste the examples
  - From Loop: Lectures > Lecture 11
  - Or from the URL: https://damien-dupre.github.io/mt5000/lectures/lecture_11

2. In another tab, go to: https://rstudio.cloud/
  - Sign in or Sign up (if not already done)
  - In your workspace, Click "Untitled Project" or "New Project" (if not already done) 

```{r echo=FALSE, out.width='100%'}
knitr::include_graphics("https://miro.medium.com/max/1400/1*JBHNRwGr3ZiyBzYWpvH6zg.png")
```

---

# The gapminder Dataset

The dataset used today is stored in the {gapminder} package into an object called `gapminder`. 

Each row in this table corresponds to a country at a specific year. For each row, we have 6 columns:

- **country**: Name of country.
- **year**: Year of the observation (between 1952 and 2007).
- **pop**: Number of people living in the country.
- **continent**: Which of the five continents the country is part of. 
- **lifeExp**: Life expectancy in years.
- **gdpPercap**: Gross domestic product (in US dollars).

```{r eval=FALSE}
#install.packages("gapminder")
library(gapminder)
str(gapminder)
```

---

class: inverse, mline, center, middle

# 1. Linear Regression Models in R

---

# Variables and Hypotheses

---

# Variables and Hypotheses

Remember, for each hypothesis, let's denote the:

- **"variable being explained"** as Y (also called Dependent Variable (DV) or Outcome). This variable has to be unique and made of numeric values (i.e., continuous).
- **"variables doing the explaining"** as X, Z, ... (also called Independent Variables (IV) or Predictors). An hypothesis contains only one variable if this hypothesis states a main effect, and it contains two or more variables if this hypothesis is an interaction. The variable(s) can be either made of character strings (i.e., categorical) or made of numeric values (i.e., continuous).

Multiple hypotheses having the same Outcome variable have to be tested in the same time in a model:

$$Outcome = Model + Error$$

---

# Model and Equations

A model contains:

- Only one Outcome/Dependent Variable
- One or more Predictor/Independent Variables of any type (categorical or continuous)
- Main and/or Interaction Effects

To evaluate their relationship with the outcome, each effect hypothesis is related with a coefficient called **Estimate** and represented with $\beta$ as follow:

$$Outcome = \beta_0 + \beta_1 Pred1 + \beta_2 Pred2 + \beta_3 Pred1 * Pred2 + \epsilon$$

Testing for the significance of the effect means evaluating if this estimate $\beta$ value is significantly **different, higher or lower than 0** as hypothesised in $H_a$ by the scientist.

---

# Estimates and Linear Regression in R

The `lm()` function calculate each estimate and test them against 0 for you.

`lm()` has only two arguments that you should care about: `formula` and `data`. 

- `formula` is the translation of the equation of the model

- `data` is the name of the data frame object containing the variables.

Here is a generic example:

```{r eval=FALSE}
lm(formula = Outcome ~ Pred1 + Pred2, data = my_data_object)
```

Here is an example with {gapminder}:

```{r}
lm(formula = lifeExp ~ gdpPercap + year, data = gapminder)
```

---

# Mastering the Formula

`lm()` has only one difficulty, the `formula`. The `formula` is the direct translation of the equation tested but with its own representation:

1. The = sign is replaced by `~` (read according to)
2. Each predictor is added with the `+` sign
3. An interaction effect uses the symbol `:` instead of *

Here are some generic equations and their conversion in `formula`:

$$Outcome = \beta_0 + \beta_1 Pred1 + \beta_2 Pred2 + \epsilon$$

```{r eval=FALSE}
lm(formula = Outcome ~ Pred1 + Pred2, data = my_data_object)
```

$$Outcome = \beta_0 + \beta_1 Pred1 + \beta_2 Pred2 + \beta_3 Pred3 + \epsilon$$

```{r eval=FALSE}
lm(formula = Outcome ~ Pred1 + Pred2 + Pred3, data = my_data_object)
```

$$Outcome = \beta_0 + \beta_1 Pred1 + \beta_2 Pred2 + \beta_3 Pred1*Pred2 + \epsilon$$

```{r eval=FALSE}
lm(formula = Outcome ~ Pred1 + Pred2 + Pred1 : Pred2, data = my_data_object)
```

---

# Mastering the Formula

Here are some equations from the gapminder dataset and their conversion in `formula`:

--

$$lifeExp = \beta_0 + \beta_1 gdpPercap + \beta_2 year + \epsilon$$

```{r}
lm(formula = lifeExp ~ gdpPercap + year, data = gapminder)
```

--

$$lifeExp = \beta_0 + \beta_1 gdpPercap + \beta_2 year + \beta_3 gdpPercap * year + \epsilon$$

```{r}
lm(formula = lifeExp ~ gdpPercap + year + gdpPercap : year , data = gapminder)
```

---
class: title-slide, middle

## Live Demo

---
class: title-slide, middle

## Exercise

Test the following models in RStudio Cloud:

$$pop = \beta_0 + \beta_1 gdpPercap + \beta_2 lifeExp + \epsilon$$

$$pop = \beta_0 + \beta_1 gdpPercap + \beta_2 lifeExp + \beta_3 gdpPercap * lifeExp + \epsilon$$

```{r echo=FALSE}
countdown(minutes = 5, warn_when = 60)
```

---

class: inverse, mline, center, middle

# 2. Hypothesis Testing in R

---

# LM Summary

While the function `lm()` computes the model, the function `summary()` display the results

```{r}
model_gapminder <- lm(formula = lifeExp ~ gdpPercap + year, data = gapminder)

summary(model_gapminder)
```

---

# LM Summary

The output of the `summary()` function is pretty dense, but let's analyse it line by line. 

The first line reminds us of what the actual regression model is:

```
Call:
lm(formula = lifeExp ~ gdpPercap + year, data = gapminder)
```

The next part provides a quick summary of the residuals (i.e., the &epsilon; values),

```
Residuals:
    Min      1Q  Median      3Q     Max 
-67.262  -6.954   1.219   7.759  19.553 
```

This can be convenient as a quick check that the model is okay. **Linear regression assumes that these residuals were normally distributed, with mean 0.** In particular it’s worth quickly checking to see if the median is close to zero, and to see if the first quartile is about the same size as the third quartile. If they look badly off, there’s a good chance that the assumptions of regression are violated. 

---

# LM Summary

The next part of the R output looks at the coefficients of the regression model:

```
Coefficients:
                 Estimate    Std. Error t value            Pr(>|t|)    
(Intercept) -418.42425945   27.61713769  -15.15 <0.0000000000000002 ***
gdpPercap      0.00066973    0.00002447   27.37 <0.0000000000000002 ***
year           0.23898275    0.01397107   17.11 <0.0000000000000002 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
```

Each row in this table refers to one of the coefficient estimated in the regression model. 

The first row is the intercept term, and the later ones look at each of the predictors. The columns give you all of the relevant information:
- The first column is the actual estimate of b (e.g., -418.42425945 for the intercept, 0.00066973 for gdpPercap and 0.23898275 for year). 
- The second column is the standard error estimate (SE). 
- The third column gives you the t-statistic. 
- Finally, the fourth column gives you the actual p value for each of these tests. 

---

# LM Summary

The only thing that the previous table doesn’t list is the degrees of freedom used in the t-test, which is always N−K−1 and is listed immediately below, in this line:

```
Residual standard error: 9.694 on 1701 degrees of freedom
```

The value of df=1701 is equal to N−K−1, so that’s what we use for our t-tests. In the final part of the output we have the F-test and the R<sup>2</sup> values which assess the performance of the model as a whole

```
Multiple R-squared:  0.4375,	Adjusted R-squared:  0.4368 
F-statistic: 661.4 on 2 and 1701 DF,  p-value: < 0.00000000000000022
```

So in this case, the model did not perform significantly better than you’d expect by chance (F(2,1701) = 661.4, p < 0.001), which isn’t all that surprising: the R<sup>2</sup> = 0.4375 value indicate that the regression model accounts for 43.7% of the variability in the outcome measure. 

When we look back up at the t-tests for each of the individual coefficients, we have pretty strong evidence that gdpPercap and year have a significant effect. 

---

# Reporting Clean Results

To communicate about your statistical analyses in an academic report, the simplest method is to find the values in the `summary()` output and to copy-paste them in the text according to the format expected that we have seen in the previous lectures.

However, this task can be long, difficult and lead to human errors. Thankfully, R has additional packages that are providing alternative functions to read linear regression models and communicate results. Because there are too many packages, I will focus only on one additional packages: {report}.

```{r echo=FALSE}
include_graphics("https://memegenerator.net/img/instances/73408711/whoa-i-know-linear-regression.jpg")
```

---

# Automatic Results with {report}

All the previous packages installed so far were hosted on the CRAN website (Comprehensive R Archive Network). However some very good packages are also hosted on GitHub.com and this is the case of {report}. To install {report}, the {remote} package has to be installed as well as follow:

```{r eval=FALSE}
install.packages("remotes")

remotes::install_github("easystats/report")
```

The package {report} will print a text containing all the statistics already in sentences ready to be interpreted (see https://easystats.github.io/report/).

To print the statistical analyses:

1. Load the package {report}
2. Create an object containing the output of the function `lm()`
3. Use this object as input of the function `report()` from the {report} package

**Note: If used in a RMarkdown document, the chunk containing `report()` has to include the chunk option `results='asis'`**

---

# Automatic Results with {report}

````markdown
`r ''````{r results='asis'}
library(report)

model_gapminder <- lm(formula = lifeExp ~ gdpPercap + year, data = gapminder)

report(model_gapminder)
```
````

```{r echo=FALSE, results='asis'}
library(report)

model_gapminder <- lm(formula = lifeExp ~ gdpPercap + year, data = gapminder)

report(model_gapminder)
```

---

# Automatic Results with {report}

Output of `report()` if `results='asis'` is missing:

````markdown
`r ''````{r}
library(report)

model_gapminder <- lm(formula = lifeExp ~ gdpPercap + year, data = gapminder)

report(model_gapminder)
```
````

```{r echo=FALSE}
library(report)

model_gapminder <- lm(formula = lifeExp ~ gdpPercap + year, data = gapminder)

report(model_gapminder)
```

---
class: title-slide, middle

## Live Demo

---
class: title-slide, middle

## Exercise

In RStudio Cloud, check the `report()` output from the `lm()` function testing the following models:

$$pop = \beta_0 + \beta_1 gdpPercap + \beta_2 lifeExp + \epsilon$$

$$pop = \beta_0 + \beta_1 gdpPercap + \beta_2 lifeExp + \beta_3 gdpPercap * lifeExp + \epsilon$$

```{r echo=FALSE}
countdown(minutes = 5, warn_when = 60)
```

---
class: inverse, mline, left, middle

<img class="circle" src="https://github.com/damien-dupre.png" width="250px"/>

# Thanks for your attention and don't hesitate to ask any questions!

[`r fa(name = "twitter")` @damien_dupre](http://twitter.com/damien_dupre)  
[`r fa(name = "github")` @damien-dupre](http://github.com/damien-dupre)  
[`r fa(name = "link")` damien-datasci-blog.netlify.app](https://damien-datasci-blog.netlify.app)  
[`r fa(name = "paper-plane")` damien.dupre@dcu.ie](mailto:damien.dupre@dcu.ie)
